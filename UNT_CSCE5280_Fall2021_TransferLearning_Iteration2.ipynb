{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UNT_CSCE5280_Fall2021_TransferLearning_Iteration2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LoriSchuan-dev/transferLearning_AIwearable/blob/main/UNT_CSCE5280_Fall2021_TransferLearning_Iteration2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8_XXscf_A9J"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import platform\n",
        "\n",
        "#!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "#from google.colab import drive\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "os.getcwd()\n",
        "os.listdir()\n",
        "#drive.mount('/content/drive')\n",
        "#os.getcwd()\n",
        "#os.listdir(\"./drive/MyDrive\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlVzPmm__Zl5"
      },
      "source": [
        "# cloning our team's repo on github\n",
        "#!git clone https://github.com/LoriSchuan-dev/transferLearning_AIwearable.git\n",
        "#os.listdir()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxy4xnLhVe9M"
      },
      "source": [
        "## **Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWqHhcIXVfYd"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def make_confusion_matrix(cf,\n",
        "                          group_names=None,\n",
        "                          categories='auto',\n",
        "                          count=True,\n",
        "                          percent=True,\n",
        "                          cbar=True,\n",
        "                          xyticks=True,\n",
        "                          xyplotlabels=True,\n",
        "                          sum_stats=True,\n",
        "                          figsize=None,\n",
        "                          cmap='Blues',\n",
        "                          title=None):\n",
        "    '''\n",
        "    This function will make a pretty plot of an sklearn Confusion Matrix cm using a Seaborn heatmap visualization.\n",
        "    Arguments\n",
        "    ---------\n",
        "    cf:            confusion matrix to be passed in\n",
        "    group_names:   List of strings that represent the labels row by row to be shown in each square.\n",
        "    categories:    List of strings containing the categories to be displayed on the x,y axis. Default is 'auto'\n",
        "    count:         If True, show the raw number in the confusion matrix. Default is True.\n",
        "    normalize:     If True, show the proportions for each category. Default is True.\n",
        "    cbar:          If True, show the color bar. The cbar values are based off the values in the confusion matrix.\n",
        "                   Default is True.\n",
        "    xyticks:       If True, show x and y ticks. Default is True.\n",
        "    xyplotlabels:  If True, show 'True Label' and 'Predicted Label' on the figure. Default is True.\n",
        "    sum_stats:     If True, display summary statistics below the figure. Default is True.\n",
        "    figsize:       Tuple representing the figure size. Default will be the matplotlib rcParams value.\n",
        "    cmap:          Colormap of the values displayed from matplotlib.pyplot.cm. Default is 'Blues'\n",
        "                   See http://matplotlib.org/examples/color/colormaps_reference.html\n",
        "                   \n",
        "    title:         Title for the heatmap. Default is None.\n",
        "    '''\n",
        "\n",
        "\n",
        "    # CODE TO GENERATE TEXT INSIDE EACH SQUARE\n",
        "    blanks = ['' for i in range(cf.size)]\n",
        "\n",
        "    if group_names and len(group_names)==cf.size:\n",
        "        group_labels = [\"{}\\n\".format(value) for value in group_names]\n",
        "    else:\n",
        "        group_labels = blanks\n",
        "\n",
        "    if count:\n",
        "        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n",
        "    else:\n",
        "        group_counts = blanks\n",
        "\n",
        "    if percent:\n",
        "        group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten()/np.sum(cf)]\n",
        "    else:\n",
        "        group_percentages = blanks\n",
        "\n",
        "    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]\n",
        "    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n",
        "\n",
        "\n",
        "    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS\n",
        "    if sum_stats:\n",
        "        #Accuracy is sum of diagonal divided by total observations\n",
        "        accuracy  = np.trace(cf) / float(np.sum(cf))\n",
        "\n",
        "        #if it is a binary confusion matrix, show some more stats\n",
        "        if len(cf)==2:\n",
        "            #Metrics for Binary Confusion Matrices\n",
        "            precision = cf[1,1] / sum(cf[:,1])\n",
        "            recall    = cf[1,1] / sum(cf[1,:])\n",
        "            f1_score  = 2*precision*recall / (precision + recall)\n",
        "            stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(\n",
        "                accuracy,precision,recall,f1_score)\n",
        "        else:\n",
        "            stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\n",
        "    else:\n",
        "        stats_text = \"\"\n",
        "\n",
        "\n",
        "    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS\n",
        "    if figsize==None:\n",
        "        #Get default figure size if not set\n",
        "        figsize = plt.rcParams.get('figure.figsize')\n",
        "\n",
        "    if xyticks==False:\n",
        "        #Do not show categories if xyticks is False\n",
        "        categories=False\n",
        "\n",
        "\n",
        "    # MAKE THE HEATMAP VISUALIZATION\n",
        "    plt.figure(figsize=figsize)\n",
        "    sns.heatmap(cf,annot=box_labels,fmt=\"\",cmap=cmap,cbar=cbar,xticklabels=categories,yticklabels=categories)\n",
        "\n",
        "    if xyplotlabels:\n",
        "        plt.ylabel('True label')\n",
        "        plt.xlabel('Predicted label' + stats_text)\n",
        "    else:\n",
        "        plt.xlabel(stats_text)\n",
        "    \n",
        "    if title:\n",
        "        plt.title(title)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Z3BHSrhTULw"
      },
      "source": [
        "# **DATASET**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3N1eynOQ_-TN"
      },
      "source": [
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "#gauth = GoogleAuth()\n",
        "#gauth.credentials = GoogleCredentials.get_application_default()\n",
        "#gDrive = GoogleDrive(gauth)\n",
        "\n",
        "\n",
        "# download the dataset from our team's shared folder on google drive\n",
        "!gdown --id '1X3vtb0ZPQBgv6Fdu_iHul9PNGbSnJqGN'\n",
        "\n",
        "# check if download successful\n",
        "#os.listdir()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mlwf6HBOAC4Y"
      },
      "source": [
        "# extract from the dataset compressed package\n",
        "!unzip \"gestures-dataset.zip\"\n",
        "# check if extraction successful\n",
        "os.listdir(\"./gestures-dataset\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qz430g75Xjhh",
        "outputId": "b581fe4b-bbc1-4d47-851a-87df584a088a"
      },
      "source": [
        ""
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/\n",
            "/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['lib64',\n",
              " 'home',\n",
              " 'media',\n",
              " 'tmp',\n",
              " 'opt',\n",
              " 'run',\n",
              " 'sbin',\n",
              " 'sys',\n",
              " 'mnt',\n",
              " 'root',\n",
              " 'dev',\n",
              " 'lib',\n",
              " 'usr',\n",
              " 'proc',\n",
              " 'srv',\n",
              " 'bin',\n",
              " 'var',\n",
              " 'boot',\n",
              " 'etc',\n",
              " 'content',\n",
              " '.dockerenv',\n",
              " 'tools',\n",
              " 'datalab',\n",
              " 'tensorflow-1.15.2',\n",
              " 'lib32',\n",
              " 'python-apt']"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gmh58W6TQtq"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "gesture_subset = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12','13','14','15','16','17','18','19','20']\n",
        "\n",
        "gesture_subset.sort()\n",
        "\n",
        "print(\"Loadind Dataset for gestures: \", gesture_subset)\n",
        "\n",
        "### path to dataset, will need to change depending on where and how you run \n",
        "### i.e., google colab online or your own computer, and where do you locate files on your computer\n",
        "### preferred relative path with \"../\" or \"./\"\n",
        "### *note, on Windows, \"/path\" is relative path starting from current directory location, and equivalent to \"./path\"\n",
        "### but on Linux/Unix, \"/path\" is absolute path starting from root-directory, and root-directory is also different from the directory named \"root\" (which is a subdirectory on root-dir accessible by path \"~\")\n",
        "path = r'./gestures-dataset'\n",
        "\n",
        "samples=0\n",
        "dataset = None\n",
        "\n",
        "for subject in os.listdir(path):\n",
        "        if os.path.isfile(os.path.join(path, subject)):\n",
        "            continue\n",
        "        if subject in ('U01', 'U02', 'U03', 'U04', 'U05', 'U06', 'U07', 'U08'):\n",
        "            \n",
        "            for gesture in os.listdir(os.path.join(path, subject)):\n",
        "                \n",
        "                if os.path.isfile(os.path.join(path, subject, gesture)):\n",
        "                    \n",
        "                    continue\n",
        "                gesture = str(gesture)\n",
        "                if gesture not in gesture_subset:\n",
        "                    continue\n",
        "                \n",
        "                for samplefile in os.listdir(os.path.join(path, subject, gesture)):\n",
        "                    \n",
        "                    if os.path.isfile(os.path.join(path, subject, gesture, samplefile)):\n",
        "                        \n",
        "                        df = pd.read_csv(os.path.join(path, subject, gesture, samplefile), \\\n",
        "                            sep = ' ', \\\n",
        "                            names = ['System.currentTimeMillis()', \\\n",
        "                            'System.nanoTime()', \\\n",
        "                            'sample.timestamp', \\\n",
        "                            'X', \\\n",
        "                            'Y', \\\n",
        "                            'Z' \\\n",
        "                            ])\n",
        "                        df = df[[\"sample.timestamp\", \"X\", \"Y\", \"Z\"]]\n",
        "                        \n",
        "\n",
        "                                        \n",
        "                        start = df[\"sample.timestamp\"][0]\n",
        "                        df[\"sample.timestamp\"] -= start\n",
        "                        df[\"sample.timestamp\"] /= 10000000\n",
        "                        df[\"subject\"] = subject\n",
        "                        df[\"gesture\"] = gesture\n",
        "                        df[\"sample\"] = str(samplefile[:-4])\n",
        "                        samples += 1\n",
        "                        #print(df)\n",
        "                        \n",
        "                        if dataset is None:\n",
        "                            dataset = df.copy()\n",
        "                        else:\n",
        "                            dataset = pd.concat([dataset, df])\n",
        "\n",
        "\n",
        "dataset = dataset.sort_values(by=['gesture','subject','sample','sample.timestamp'])\n",
        "data = dataset    \n",
        "print(str(samples) + \" samples loaded\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTtK5YcKTsON"
      },
      "source": [
        "## Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46bpGfcsTvkb"
      },
      "source": [
        "print(\"Scaling Dataset for gestures: \", gesture_subset)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "dataset_scaled = None\n",
        "\n",
        "samples = 0\n",
        "\n",
        "for i, gesture in enumerate(gesture_subset):\n",
        "        df_gesture=data[data['gesture']==gesture] \n",
        "        for j, subject in enumerate(df_gesture['subject'].unique()):\n",
        "            df_subject=df_gesture[df_gesture['subject']==subject]\n",
        "            for k, sample in enumerate(df_subject['sample'].unique()):\n",
        "                df_sample=df_subject[df_subject['sample']==sample].copy()\n",
        "                df_sample.sort_values(by=['sample.timestamp'])\n",
        "\n",
        "                sc = scaler\n",
        "                sc = sc.fit_transform(df_sample[[\"X\", \"Y\", \"Z\"]])\n",
        "                sc = pd.DataFrame(data=sc, columns=[\"X\", \"Y\", \"Z\"])\n",
        "                df_sample['X'] = sc['X']\n",
        "                df_sample['Y'] = sc['Y']\n",
        "                df_sample['Z'] = sc['Z']\n",
        "                if dataset_scaled is None:\n",
        "                    dataset_scaled = df_sample.copy()\n",
        "                else:\n",
        "                    dataset_scaled = pd.concat([dataset_scaled, df_sample])\n",
        "                samples += 1\n",
        "print(str(samples) + \" samples scaled\")\n",
        "data = dataset_scaled\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAlHNrMSUHvi"
      },
      "source": [
        "## **Cleaning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wIbL1APUK-N"
      },
      "source": [
        "print(\"Cleaning Dataset for gestures: \", gesture_subset)\n",
        "\n",
        "dataset_outliers = None\n",
        "dataset_cleaned = None\n",
        "\n",
        "samples = 0\n",
        "outliers = 0\n",
        "\n",
        "for i, gesture in enumerate(gesture_subset):\n",
        "        df_gesture = data[data['gesture']==gesture]\n",
        "        for j, subject in enumerate(df_gesture['subject'].unique()):\n",
        "            df_subject = df_gesture[df_gesture['subject']==subject]\n",
        "        \n",
        "            time_mean = df_subject.groupby([\"gesture\",\"subject\", \"sample\"]).count().groupby([\"gesture\",\"subject\"]).agg({'sample.timestamp': ['mean']})\n",
        "            time_std = df_subject.groupby([\"gesture\",\"subject\", \"sample\"]).count().groupby([\"gesture\",\"subject\"]).agg({'sample.timestamp': ['std']})\n",
        "            time_max = time_mean['sample.timestamp'].iloc[0]['mean'] + 1.0 * time_std['sample.timestamp'].iloc[0]['std']\n",
        "            time_min = time_mean['sample.timestamp'].iloc[0]['mean'] - 1.0 * time_std['sample.timestamp'].iloc[0]['std']\n",
        "            for k, sample in enumerate(df_subject['sample'].unique()):\n",
        "                df_sample=df_subject[df_subject['sample']==sample]\n",
        "                df_sample_count = df_sample.count()['sample.timestamp']\n",
        "                if df_sample_count < time_min or df_sample_count > time_max:\n",
        "                    if dataset_outliers is None:\n",
        "                        dataset_outliers = df_sample.copy()\n",
        "                    else:\n",
        "                        dataset_outliers = pd.concat([dataset_outliers, df_sample])\n",
        "                    outliers += 1\n",
        "                else:\n",
        "                    if dataset_cleaned is None:\n",
        "                        dataset_cleaned = df_sample.copy()\n",
        "                    else:\n",
        "                        dataset_cleaned = pd.concat([dataset_cleaned, df_sample])\n",
        "                    samples += 1\n",
        "print(str(samples) + \" samples cleaned\")\n",
        "print(str(outliers) + \" samples outliers\")\n",
        "data = dataset_cleaned"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAxwzcemUP01"
      },
      "source": [
        "## **Time Slicing of Cleaned Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYpxdHAxUV7M"
      },
      "source": [
        "print(\"Time slicing Cleaned Dataset for gestures: \", gesture_subset)\n",
        "dataset_timecut = None\n",
        "samples = 0\n",
        "damaged = 0\n",
        "for i, gesture in enumerate(data['gesture'].unique()):\n",
        "  df_gesture = data[data['gesture']==gesture]\n",
        "  for j, subject in enumerate(df_gesture['subject'].unique()):\n",
        "    df_subject = df_gesture[df_gesture['subject']==subject] \n",
        "    time_max = 19 # 18 * 11 = 198\n",
        "    for i, sample in enumerate(df_subject['sample'].unique()):\n",
        "                df_sample = df_subject[df_subject['sample']==sample]\n",
        "                df_sample_count = df_sample.count()['sample.timestamp']\n",
        "                #print(df_sample_count)\n",
        "                if df_sample_count >= time_max:\n",
        "                    df_sample = df_sample[df_sample['sample.timestamp'] <= (11 * (time_max-1))]\n",
        "                    df_sample_count = df_sample.count()['sample.timestamp']\n",
        "                    #print(df_sample_count)\n",
        "                elif df_sample_count < time_max:\n",
        "                    for tmp in range(df_sample_count * 11, (time_max) * 11, 11):\n",
        "                        df = pd.DataFrame([[tmp, 0.0, 0.0, 0.0, gesture, subject, sample]], columns=['sample.timestamp', 'X', 'Y', 'Z', 'gesture', 'subject', 'sample'])\n",
        "                        df_sample = df_sample.append(df, ignore_index=True)            \n",
        "                #print(df_sample)\n",
        "                df_sample_count = df_sample.count()['sample.timestamp']\n",
        "                #print(df_sample_count)\n",
        "                if df_sample_count != time_max:\n",
        "                    damaged += 1\n",
        "                    continue\n",
        "                if dataset_timecut is None:\n",
        "                    dataset_timecut = df_sample.copy()\n",
        "                else:\n",
        "                    dataset_timecut = pd.concat([dataset_timecut, df_sample])\n",
        "                samples += 1\n",
        "\n",
        "dataset_cleaned = dataset_timecut\n",
        "print(str(samples) + \" cleaned samples sliced\")\n",
        "print(str(damaged) + \" cleaned samples damaged\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WANUJYHUZov"
      },
      "source": [
        "## **Slicing outliers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FArhmjRrUeAn"
      },
      "source": [
        "data = dataset_outliers\n",
        "print(\"Time slicing Outliers Dataset for gestures: \", gesture_subset)\n",
        "dataset_timecut = None\n",
        "samples = 0\n",
        "damaged = 0\n",
        "for i, gesture in enumerate(data['gesture'].unique()):\n",
        "        df_gesture = data[data['gesture']==gesture]\n",
        "        for j, subject in enumerate(df_gesture['subject'].unique()):\n",
        "            df_subject = df_gesture[df_gesture['subject']==subject] \n",
        "            time_max = 19 # 18 * 11 = 198\n",
        "            for i, sample in enumerate(df_subject['sample'].unique()):\n",
        "                df_sample = df_subject[df_subject['sample']==sample]\n",
        "                df_sample_count = df_sample.count()['sample.timestamp']\n",
        "                #print(df_sample_count)\n",
        "                if df_sample_count >= time_max:\n",
        "                    df_sample = df_sample[df_sample['sample.timestamp'] <= (11 * (time_max-1))]\n",
        "                    df_sample_count = df_sample.count()['sample.timestamp']\n",
        "                    #print(df_sample_count)\n",
        "                elif df_sample_count < time_max:\n",
        "                    for tmp in range(df_sample_count * 11, (time_max) * 11, 11):\n",
        "                        df = pd.DataFrame([[tmp, 0.0, 0.0, 0.0, gesture, subject, sample]], columns=['sample.timestamp', 'X', 'Y', 'Z', 'gesture', 'subject', 'sample'])\n",
        "                        df_sample = df_sample.append(df, ignore_index=True)            \n",
        "                #print(df_sample)\n",
        "                df_sample_count = df_sample.count()['sample.timestamp']\n",
        "                #print(df_sample_count)\n",
        "                if df_sample_count != time_max:\n",
        "                    damaged += 1\n",
        "                    continue\n",
        "                if dataset_timecut is None:\n",
        "                    dataset_timecut = df_sample.copy()\n",
        "                else:\n",
        "                    dataset_timecut = pd.concat([dataset_timecut, df_sample])\n",
        "                samples += 1\n",
        "\n",
        "dataset_outliers = dataset_timecut\n",
        "print(str(samples) + \" outliers samples sliced\")1\n",
        "print(str(damaged) + \" outliers samples damaged\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShYxzzWTUmiM"
      },
      "source": [
        "## **Hyperparameter tuning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bKWEdvvUqOG"
      },
      "source": [
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Bidirectional\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.optimizers import adam_v2\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import np_utils\n",
        "#    from scikeras.wrappers import KerasClassifier\n",
        "\n",
        "import sklearn\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "import numpy as np\n",
        " \n",
        "# fix random seed for reproducibility\n",
        "seed = 1000\n",
        "np.random.seed(seed)\n",
        "\n",
        "\n",
        "# create the dataset\n",
        "def get_dataset(data):\n",
        "    X_train = []\n",
        "    Y_train = []\n",
        "    groups = []\n",
        "    for i, gesture in enumerate(data['gesture'].unique()):\n",
        "      df_gesture = data[data['gesture']==gesture]\n",
        "      for j, subject in enumerate(df_gesture['subject'].unique()):\n",
        "              df_subject = df_gesture[df_gesture['subject']==subject]\n",
        "              for k, sample in enumerate(df_subject['sample'].unique()):\n",
        "                  df_sample = df_subject[df_subject['sample']==sample]\n",
        "                  accel_vector = []\n",
        "                  for index, row in df_sample.sort_values(by='sample.timestamp').iterrows():\n",
        "                      accel_vector.append([row['X'],row['Y'],row['Z']])\n",
        "                  accel_vector = np.asarray(accel_vector)\n",
        "                  X_train.append(accel_vector)\n",
        "                  Y_train.append(gesture)\n",
        "                  groups.append(subject)\n",
        "    X_train = np.asarray(X_train)\n",
        "    Y_train = LabelEncoder().fit_transform(Y_train)\n",
        "    #print(Y_train)\n",
        "    return X_train, Y_train, groups\n",
        "\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model(dropout_rate=0.8, units=128, optimizer=adam_v2.Adam(learning_rate=0.001)):\n",
        "    model = Sequential()\n",
        "    model.add(\n",
        "        Bidirectional(\n",
        "            LSTM(\n",
        "                units=units, \n",
        "                input_shape=[19, 3]\n",
        "            )\n",
        "        )\n",
        "    )\n",
        "    model.add(Dropout(rate=dropout_rate))\n",
        "    model.add(Dense(units=units, activation='relu'))\n",
        "    model.add(Dense(len(gesture_subset), activation='softmax'))\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    #print(model.summary())\t\n",
        "    return model\n",
        "\n",
        "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "cv = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=1000)\n",
        "    # get the dataset\n",
        "X, y, g = get_dataset(dataset_cleaned)\n",
        "    #cv = cv.split(X, y, g)\n",
        "batch_size = [19]\n",
        "epochs = [64, 128]\n",
        "    #epochs = [128]\n",
        "units = [32,64,128]\n",
        "#    units = [16]\n",
        "dropout_rate = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "#    dropout_rate = [0.5]\n",
        "param_grid = dict(epochs=epochs, units=units, batch_size=batch_size, dropout_rate=dropout_rate)\n",
        "print(\"Hyperparameter tunning started for Dataset for gestures: \", gesture_subset)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, cv=cv, verbose=1)\n",
        "grid_result = grid.fit(X, y, groups=g)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "train_mean = grid_result.cv_results_['mean_fit_time']\n",
        "train_std = grid_result.cv_results_['std_fit_time']\n",
        "score_mean = grid_result.cv_results_['mean_score_time']\n",
        "score_std = grid_result.cv_results_['std_score_time']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, train_mean, train_std, score_mean, score_std, param in zip(means, stds, train_mean, train_std, score_mean, score_std, params):\n",
        "    print(\"accuracy: %f (%f) train time: %f (%f) score time: %f (%f) with: %r\" % (mean, stdev, train_mean, train_std, score_mean, score_std, param))\n",
        "print(\"Hyperparameter tunning completed for Dataset: \", gesture_subset)\n",
        "\n",
        "\n",
        "model = grid_result.best_estimator_\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kY7CFIhtQJre"
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bdidvn9TQzi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9TdMvw9DjF7"
      },
      "source": [
        "# make new temporary folder to store results\n",
        "!mkdir results\n",
        "os.listdir()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0l4C3fItEQ0s"
      },
      "source": [
        "#gesture_subset = []\n",
        "modelStorePath = \"./results/\"\n",
        "\n",
        "import pickle\n",
        "\n",
        "def save_model(model, gesture_subset, filePath):\n",
        "    gesture_subset.sort()\n",
        "    name = '-'.join(gesture_subset)\n",
        "    # saving model\n",
        "    pickle.dump(model.classes_, open(filePath + name + '_model_classes.pkl','wb'))\n",
        "    model.model.save(name + '_lstm')\n",
        "\n",
        "import tensorflow as tf\n",
        "def load_model(gesture_subset, filePath):\n",
        "    gesture_subset.sort()\n",
        "    name = '-'.join(gesture_subset)\n",
        "    # loading model\n",
        "    build_model = lambda: tf.keras.models.load_model(name + '_lstm')\n",
        "    classifier = KerasClassifier(build_fn=build_model, epochs=1, batch_size=10, verbose=0)\n",
        "    classifier.classes_ = pickle.load(open(filePath + name + '_model_classes.pkl','rb'))\n",
        "    classifier.model = build_model()\n",
        "    return classifier\n",
        "\n",
        "print(\"Saving model to disk started for Dataset gestures: \", gesture_subset)\n",
        "#save_model(model, gesture_subset, modelStorePath)\n",
        "print(\"Saving model to disk completed for Dataset gestures: \", gesture_subset)\n",
        "\n",
        "print(\"Loading model to disk started for Dataset gestures: \", gesture_subset)\n",
        "#model = load_model(gesture_subset, modelStorePath)\n",
        "#print(model.model.summary())\n",
        "print(\"Loading model to disk completed for Dataset gestures: \", gesture_subset)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aaYA4qSGGoo"
      },
      "source": [
        "\n",
        "print(\"Testing model against outliers for Dataset gestures: \", gesture_subset)\n",
        "data = dataset_outliers\n",
        "X, y, g = get_dataset(dataset_outliers)\n",
        "y_pred = model.predict(X)\n",
        "#print(y)\n",
        "#print(y_pred)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y, y_pred, target_names=gesture_subset))    \n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cf_matrix = confusion_matrix(y, y_pred)\n",
        "make_confusion_matrix(cf_matrix, categories=gesture_subset, figsize=[8,8])\n",
        "#return grid_result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "di0_PfRtEQ3W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2XkmRIwHhBT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJwIXLk-JGpH"
      },
      "source": [
        "# **ZIP RESULTS AND UPLOAD TO TEAM's FOLDER on GG DRIVE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4CiuJZ-EQ6J"
      },
      "source": [
        "\n",
        "\n",
        "import time\n",
        "# zipping results fodler with timestamp\n",
        "resultZip = \"result_\" + str(time.time()) + \".zip\"\n",
        "print (resultZip)\n",
        "!zip $resultZip \"./results\"\n",
        "os.listdir()\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "\n",
        "# upload to our team's shared folder on gg drive\n",
        "!pip install --upgrade gupload\n",
        "!gupload --to \"17ftcqLR_52zZ8byGL_s0aXxhyP2Ko7Y3\" $resultZip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YcWoJnQH36Z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}